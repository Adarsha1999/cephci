#===============================================================================================
#----------------------------------------
#---Test Suite for Nfs Ganesha with HA---
#----------------------------------------
# Note: NFS-Ganesha with HA support only baremetal cluster
# test suite: suites/reef/nfs/tier1-nfs-ganesga-ha.yaml
#    - Bootstrap RHCS 7.0 cluster
#    - Deploy NFS-Ganesha with HA using spec file
#    - Verify NFS-Ganesha HA scenarios
#===============================================================================================
tests:
  - test:
      abort-on-fail: true
      desc: Install software pre-requisites for cluster deployment.
      module: install_prereq.py
      name: setup pre-requisites

  - test:
      abort-on-fail: true
      config:
        steps:
          - config:
              command: bootstrap
              service: cephadm
              args:
                mon-ip: node1
          - config:
              command: add_hosts
              service: host
              args:
                attach_ip_address: true
                labels: apply-all-labels
          - config:
              command: apply
              service: osd
              args:
                all-available-devices: true
          - config:
              command: apply
              service: rgw
              pos_args:
                - rgw.1
              args:
                placement:
                  label: rgw
          - config:
              args:
                - "ceph fs volume create cephfs"
              command: shell
          - config:
              args:
                placement:
                  label: mds
              base_cmd_args:
                verbose: true
              command: apply
              pos_args:
                - cephfs
              service: mds
          - config:
              args:
                - "ceph osd pool create rbd"
              command: shell
          - config:
              args:
                - "rbd pool init rbd"
              command: shell
      desc: bootstrap and deploy services.
      destroy-cluster: false
      polarion-id: CEPH-83573713
      module: test_cephadm.py
      name: Deploy cluster using cephadm

  - test:
      abort-on-fail: true
      config:
        command: add
        id: client.1
        node: node6
        install_packages:
          - ceph-common
          - ceph-fuse
        copy_admin_keyring: true
      desc: Configure the RGW,RBD client system
      destroy-cluster: false
      module: test_client.py
      name: configure client

  - test:
      abort-on-fail: true
      config:
        command: add
        id: client.2
        node: node7
        install_packages:
          - ceph-common
          - ceph-fuse
        copy_admin_keyring: true
      desc: Configure the RGW,RBD client system
      destroy-cluster: false
      module: test_client.py
      name: configure client

  - test:
      abort-on-fail: true
      config:
        command: add
        id: client.3
        node: node8
        install_packages:
          - ceph-common
          - ceph-fuse
        copy_admin_keyring: true
      desc: Configure the RGW,RBD client system
      destroy-cluster: false
      module: test_client.py
      name: configure client

  - test:
      abort-on-fail: true
      config:
        command: add
        id: client.4
        node: node9
        install_packages:
          - ceph-common
          - ceph-fuse
        copy_admin_keyring: true
      desc: Configure the RGW,RBD client system
      destroy-cluster: false
      module: test_client.py
      name: configure client

  - test:
      name: NFS-Ganesha cluster with HA using spec file
      desc: Deploy nfs-ganesha cluster with HA using spec file
      module: test_cephadm.py
      polarion-id: CEPH-83577557
      config:
        steps:
          - config:
              command: apply_spec
              service: orch
              validate-spec-services: true
              specs:
                - service_type: nfs
                  service_id: nfs-service
                  placement:
                    nodes:
                      - node2
                      - node3
                  spec:
                    port: 3333
          - config:
              command: apply_spec
              service: orch
              validate-spec-services: true
              specs:
                - service_type: ingress
                  service_id: nfs.nfs-service
                  placement:
                    count: 2
                  spec:
                    backend_service: nfs.nfs-service
                    frontend_port: 2049
                    monitor_port: 9000
                    virtual_ip: 10.8.128.255/21

  - test:
      name: nfs-ganesha-ha readdir operations
      desc: nfs-ganesha-ha with rm from c1, file creation from c2 and lookups from c3
      module: nfs_ha_readdir_operation.py
      polarion-id: CEPH-83577591
      abort-on-fail: false
      config:
        nfs_version: 4.1
        clients: 3
        servers: 2
        file_count: 100
        ha: true
        vip: 10.8.128.255/21
        operations:
          client01 : create_files
          client02 : remove_files
          client03 : perform_lookups

  - test:
      name: nfs-ganesha-ha readdir operations
      desc: nfs-ganesha-ha with create file from c1, linux untar from c2, lookups from c3 and du-sh from c4
      module: nfs_ha_readdir_operation.py
      polarion-id: CEPH-83577592
      abort-on-fail: false
      config:
        nfs_version: 4.1
        clients: 4
        servers: 2
        file_count: 100
        ha: true
        vip: 10.8.128.255/21
        operations:
          client01 : create_files
          client02 : perfrom_linux_untar
          client03 : perform_lookups
          client04 : perfrom_du_sh

  - test:
      name: Nfs Verify failover with IO
      module: nfs_verify_failover_with_io.py
      desc:  Verify failover and check the IO completes and VIP got failover to another node
      polarion-id: CEPH-83577564
      abort-on-fail: false
      config:
        nfs_version: 4.1
        clients: 4
        servers: 2
        ha: true
        vip: 10.8.128.255/21

  - test:
      name: Nfs Verify pynfs with HA
      module: nfs_verify_pynfs_ha.py
      desc: Verify Pynfs tests with HA cluster
      polarion-id: CEPH-83577565
      abort-on-fail: false
      config:
        nfs_version: 4.1
        clients: 4
        servers: 2
        ha: true
        vip: 10.8.128.255/21

  - test:
      name: Nfs Verify file lock with HA
      module: nfs_verify_file_lock_ha.py
      desc: Verify file lock with HA cluster
      polarion-id: CEPH-83575956
      abort-on-fail: false
      config:
        nfs_version: 4.1
        clients: 4
        servers: 2
        ha: true
        vip: 10.8.128.255/21

  - test:
      name: Nfs Verify kill ganesha process and perform failover
      module: nfs_verify_nfs_kill_process_failover.py
      desc:  Verify failover when nfs ganesha process is killed on nfs node
      polarion-id: CEPH-83577568
      abort-on-fail: false
      config:
        nfs_version: 4.1
        clients: 4
        servers: 3
        ha: true
        vip: 10.8.130.50/21

  - test:
      name: Nfs-Ganesha-HA perform failover and delete the files
      module: nfs_verify_failover_with_file_ops.py
      desc:  Verify perform failover and delete the files from Client 2, Check files deleted
      polarion-id: CEPH-83577571
      abort-on-fail: false
      config:
        nfs_version: 4.1
        clients: 2
        servers: 2
        file_count: 3
        ha: true
        vip: 10.8.128.255/21
        operations:
          client01 : create_files
          client02 : remove_files

  - test:
      name: Nfs-Ganesha-HA perform failover and modify the files
      module: nfs_verify_failover_with_file_ops.py
      desc:  Verify perform failover and modify the files from Client 2, Check files modify
      polarion-id: CEPH-83577572
      abort-on-fail: false
      config:
        nfs_version: 4.1
        clients: 2
        servers: 2
        file_count: 3
        ha: true
        vip: 10.8.128.255/21
        operations:
          client01 : create_files

  - test:
      name: Nfs-Ganesha perform failover and modify the export file to make volume as RO
      module: nfs_ha_failover_edit_export_config_with_ro.py
      desc:  Verify perform failover and modify the export file to make volume as RO
      polarion-id: CEPH-83577573
      abort-on-fail: false
      config:
        nfs_version: 4.1
        clients: 1
        servers: 3
        ha: true
        vip: 10.8.130.255/21

  - test:
      name: Nfs-Ganesha perform failover and modify client permission in export block
      module: nfs_ha_failover_edit_export_config_client_permission.py
      desc:  Verify perform failover and modify client permission in export block
      polarion-id: CEPH-83577574
      abort-on-fail: false
      config:
        nfs_version: 4.1
        clients: 2
        servers: 3
        ha: true
        vip: 10.8.130.255/21

  - test:
      name: Nfs-Ganesha perform failover when linux untar is running
      module: nfs_ha_failover_with_untar.py
      desc:  Nfs-Ganesha perform failover when linux untar is running
      polarion-id: CEPH-83577569
      abort-on-fail: false
      config:
        nfs_version: 4.1
        clients: 1
        servers: 3
        ha: true
        vip: 10.8.129.133/21

  - test:
      name: Nfs-Ganesha perform failover and delete the export, check the export list
      module: nfs_ha_failover_delete_export.py
      desc:  Nfs-Ganesha perform failover and delete the export and when failback happens check the export list
      polarion-id: CEPH-83577570
      abort-on-fail: false
      config:
        nfs_version: 4.1
        clients: 1
        no_export_per_client: 10
        servers: 3
        ha: true
        vip: 10.8.129.133/21
