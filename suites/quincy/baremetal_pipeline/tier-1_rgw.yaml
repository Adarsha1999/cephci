# RGW build evaluation
# The following evaluations are carried out
# - Build can be deployed using CephADM
# - The cluster health is good
# - End users can perform object operations.

# tested with conf file: conf/quincy/baremetal_pipeline/mero_conf.yaml

tests:

  # Cluster deployment stage

  - test:
      abort-on-fail: true
      desc: Install software pre-requisites for cluster deployment.
      module: install_prereq.py
      name: setup pre-requisites

  - test:
      abort-on-fail: true
      config:
        verify_cluster_health: true
        steps:
          - config:
              command: bootstrap
              service: cephadm
              args:
                registry-url: registry.redhat.io
                mon-ip: node1
                initial-dashboard-password: admin@123
                dashboard-password-noupdate: true
                orphan-initial-daemons: true
                skip-monitoring-stack: true
          - config:
              command: add_hosts
              service: host
              args:
                attach_ip_address: true
                labels: apply-all-labels
          - config:
              command: apply
              service: osd
              args:
                all-available-devices: true
          - config:
              command: apply
              service: rgw
              pos_args:
                - rgw.1
              args:
                placement:
                  label: rgw
      desc: bootstrap with registry-url option and deployment services.
      destroy-cluster: false
      polarion-id: CEPH-83573713
      module: test_cephadm.py
      name: RHCS deploy cluster using cephadm

  - test:
      abort-on-fail: true
      config:
        command: add
        id: client.1
        node: node6
        install_packages:
          - ceph-common
        copy_admin_keyring: true
        git_clone: true
        git_node_role: rgw
      desc: Configure the RGW client system
      polarion-id: CEPH-83573758
      destroy-cluster: false
      module: test_client.py
      name: configure client

  - test:
      abort-on-fail: true
      clusters:
        ceph-pri:
          config:
            cephadm: true
            commands:
              - "radosgw-admin realm create --rgw-realm india --default"
              - "radosgw-admin zonegroup create --rgw-realm india --rgw-zonegroup shared --endpoints http://{node_ip:folio15}:8080,http://{node_ip:folio16}:8080,http://{node_ip:folio17}:8080,http://{node_ip:folio18}:8080,http://{node_ip:folio19}:8080 --master --default"
              - "radosgw-admin zone create --rgw-realm india --rgw-zonegroup shared --rgw-zone primary --endpoints http://{node_ip:folio15}:8080,http://{node_ip:folio16}:8080,http://{node_ip:folio17}:8080,http://{node_ip:folio18}:8080,http://{node_ip:folio19}:8080 --master --default"
              - "radosgw-admin period update --rgw-realm india --commit"
              - "radosgw-admin user create --uid=repuser --display_name='Replication user' --access-key test123 --secret test123 --rgw-realm india --system"
              - "radosgw-admin zone modify --rgw-realm india --rgw-zonegroup shared --rgw-zone primary --access-key test123 --secret test123"
              - "radosgw-admin period update --rgw-realm india --commit"
              - "ceph config set client.rgw.* rgw_realm india"
              - "ceph config set client.rgw.* rgw_zonegroup shared"
              - "ceph config set client.rgw.* rgw_zone primary"
              - "ceph orch restart rgw.shared.pri.8080"
        ceph-sec:
          config:
            cephadm: true
            commands:
              - "sleep 120"
              - "radosgw-admin realm pull --rgw-realm india --url http://folio15:8080 --access-key test123 --secret test123 --default"
              - "radosgw-admin period pull --url http://folio15:8080 --access-key test123 --secret test123"
              - "radosgw-admin zone create --rgw-realm india --rgw-zonegroup shared --rgw-zone secondary --endpoints http://{node_ip:folio20}:8080,http://{node_ip:folio21}:8080,http://{node_ip:folio22}:8080,http://{node_ip:folio23}:8080,http://{node_ip:folio24}:8080 --access-key test123 --secret test123"
              - "radosgw-admin period update --rgw-realm india --commit"
              - "ceph config set client.rgw.* rgw_realm india"
              - "ceph config set client.rgw.* rgw_zonegroup shared"
              - "ceph config set client.rgw.* rgw_zone secondary"
              - "ceph orch restart rgw.shared.sec.8080"
      desc: Setting up RGW multisite replication environment
      module: exec.py
      name: setup multisite
      polarion-id: CEPH-10362

  - test:
      name: Parallel run
      desc: RGW tier-0 parallelly.
      module: test_parallel.py
      parallel:
        - test:
            config:
              script-name: test_Mbuckets_with_Nobjects.py
              config-file-name: test_Mbuckets_with_Nobjects.yaml
              timeout: 300
              install_common: false
              run-on-rgw: true
            desc: test to create "M" no of buckets and "N" no of objects
            module: sanity_rgw.py
            name: Test M buckets with N objects
            polarion-id: CEPH-9789

        - test:
            config:
              script-name: test_Mbuckets_with_Nobjects.py
              config-file-name: test_Mbuckets_with_Nobjects_delete.yaml
              timeout: 300
              install_common: false
              run-on-rgw: true
            desc: test to create "M" no of buckets and "N" no of objects with delete
            module: sanity_rgw.py
            name: Test delete using M buckets with N objects
            polarion-id: CEPH-14237

        - test:
            config:
              script-name: test_Mbuckets_with_Nobjects.py
              config-file-name: test_Mbuckets_with_Nobjects_download.yaml
              timeout: 300
              install_common: false
              run-on-rgw: true
            desc: test to create "M" no of buckets and "N" no of objects with download
            module: sanity_rgw.py
            name: Test download with M buckets with N objects
            polarion-id: CEPH-14237

        - test:
            config:
              script-name: test_Mbuckets_with_Nobjects.py
              config-file-name: test_Mbuckets_with_Nobjects_multipart.yaml
              timeout: 300
              install_common: false
              run-on-rgw: true
            desc: test to create "M" no of buckets and "N" no of objects with multipart upload
            module: sanity_rgw.py
            name: Test multipart upload of M buckets with N objects
            polarion-id: CEPH-9801

        - test:
            config:
              script-name: test_swift_basic_ops.py
              config-file-name: test_swift_basic_ops.yaml
              timeout: 300
              install_common: false
              run-on-rgw: true
            desc: Test object operations with swift
            module: sanity_rgw.py
            name: Swift based tests
            polarion-id: CEPH-11019
